{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff0b18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/js/md3h5nb949j7585pm47mjshh0000gn/T/ipykernel_74483/2966484520.py:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a751b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_1_data.mat exp_3_data.mat exp_5_data.mat \u001b[34mpreprocessed\u001b[m\u001b[m\r\n",
      "exp_2_data.mat exp_4_data.mat exp_6_data.mat readme.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/gordon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0867a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165454c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data/gordon\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d3e04",
   "metadata": {},
   "source": [
    "## Process of Acceleration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ffd65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"data/gordon/preprocessed/acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f137b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:  1886252.0\n",
      "Unit time (s):  0.0016222646814953675\n"
     ]
    }
   ],
   "source": [
    "exps = []\n",
    "#Load experiments data\n",
    "for i in range(1,7):\n",
    "    exp = scipy.io.loadmat(os.path.join(folder, \"exp_%d_data.mat\"%i))\n",
    "    exps.append(exp)\n",
    "    \n",
    "#compute total time\n",
    "total_time = 0\n",
    "for i in range(6):\n",
    "    time_max = exps[i][\"mAcc\"][:,1].max()\n",
    "    time_min = exps[i][\"mAcc\"][:,1].min()\n",
    "    total_time += time_max-time_min\n",
    "    \n",
    "print(\"Total time: \", total_time)\n",
    "\n",
    "#compute unit time(s)\n",
    "#Total experiment time: 51min\n",
    "timeunit = (51*60)/total_time\n",
    "print(\"Unit time (s): \", timeunit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e08762a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1\n",
      "Min length of Exp0: 2634\n",
      "Experiment 2\n",
      "Min length of Exp1: 2669\n",
      "Experiment 3\n",
      "Min length of Exp2: 2710\n",
      "Experiment 4\n",
      "Min length of Exp3: 2642\n",
      "Experiment 5\n",
      "Min length of Exp4: 2281\n"
     ]
    }
   ],
   "source": [
    "#Group configuration of agents\n",
    "groups = [[[1,2,3,4,5,6,7,9,10,11]],\n",
    "          [[1,2,3,4,5],[6,7,9,10,11]],\n",
    "          [[1,2,3],[4,5,6],[7,9],[10,11]],\n",
    "          [[1],[2],[3],[4],[5],[6],[7],[9],[10],[11]],\n",
    "          [[1,2,3,5],[4,6,7],[9,10,11]],\n",
    "          [[1,2,3,4,5,6],[7,9,10,11]]]\n",
    "\n",
    "group_relations = []\n",
    "mAcc_data = []\n",
    "columns = [\"ExpID\",\"TS\",\"userID\",\"gID\",\"isLeader\", \"xAcc\", \"yAcc\",\"zAcc\", \"magACC\"]\n",
    "\n",
    "for exp_id in range(len(exps)-1):    \n",
    "    print(\"Experiment %d\"%(exp_id+1))\n",
    "    extract_mAcc_expi = []\n",
    "    expi_df = pd.DataFrame(exps[exp_id][\"mAcc\"], columns=columns)\n",
    "    #extract userIDs\n",
    "    userIDs = expi_df[\"userID\"].unique()\n",
    "    userIDs_map = {userID:idx for idx, userID in enumerate(userIDs)}\n",
    "    \n",
    "    #create group relations\n",
    "    gr_i = np.zeros((10,10))\n",
    "    groups_i = groups[exp_id]\n",
    "    groups_i_converted = []\n",
    "    for group in groups_i:\n",
    "        group_converted = [userIDs_map[user] for user in group]\n",
    "        groups_i_converted.append(group_converted)\n",
    "    for group in groups_i_converted:\n",
    "        for i in group:\n",
    "            for j in group:\n",
    "                gr_i[i,j]=1\n",
    "    group_relations.append(gr_i)\n",
    "    \n",
    "    #mapping userIDs in pandas dataframe\n",
    "    expi_df[\"userID_new\"] = expi_df[\"userID\"].apply(lambda x:userIDs_map[x])\n",
    "    expi_df[\"TS_new\"] = expi_df[\"TS\"].apply(lambda x:timeunit*x)\n",
    "    expi_df[\"Timestamp\"] = expi_df[\"TS_new\"].apply(lambda x: pd.Timestamp(x, unit='s'))\n",
    "    expi_df = expi_df.set_index(\"Timestamp\")\n",
    "    \n",
    "    #get common time interval\n",
    "    max_start = expi_df[expi_df[\"userID_new\"]==0].index.min()\n",
    "    min_end = expi_df[expi_df[\"userID_new\"]==0].index.max()\n",
    "    for userID in range(10):        \n",
    "        start = expi_df[expi_df[\"userID_new\"]==userID].index.min()\n",
    "        end = expi_df[expi_df[\"userID_new\"]==userID].index.max()\n",
    "        if start > max_start:\n",
    "            max_start = start\n",
    "        if end < min_end:\n",
    "            min_end = end       \n",
    "        \n",
    "    for userID in range(10):    \n",
    "        expi_df_userID = expi_df[expi_df.userID_new==userID]\n",
    "        resampled = expi_df_userID[expi_df_userID.userID_new==userID].resample(\"200ms\", origin=max_start).mean()\n",
    "        resampled = resampled.interpolate()#interpolate nan values\n",
    "        data = resampled[[\"xAcc\", \"yAcc\", \"zAcc\"]].values\n",
    "        extract_mAcc_expi.append(data)\n",
    "    \n",
    "    #compute length\n",
    "    min_length = np.inf    \n",
    "    for i in range(len(extract_mAcc_expi)):\n",
    "        data = extract_mAcc_expi[i]\n",
    "        length = data.shape[0]\n",
    "        if length < min_length:\n",
    "            min_length = length\n",
    "            \n",
    "    print(\"Min length of Exp%d:\"%exp_id, min_length)    \n",
    "    for i in range(len(extract_mAcc_expi)):\n",
    "        data = extract_mAcc_expi[i]\n",
    "        data = data[:min_length]\n",
    "        extract_mAcc_expi[i] = data\n",
    "        \n",
    "    extract_mAcc_expi = np.array(extract_mAcc_expi)   \n",
    "    mAcc_data.append(extract_mAcc_expi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02625658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e1aa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b942601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94397bdf",
   "metadata": {},
   "source": [
    "### Create Training, Validation and Test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b868f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Examples:  1286\n",
      "Train index:  771\n",
      "Valid index:  1028\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "labels = []\n",
    "\n",
    "window_length = 20\n",
    "\n",
    "for expID in range(5):\n",
    "    data_i = mAcc_data[expID]\n",
    "    label_i = group_relations[expID]\n",
    "    \n",
    "    time_length = data_i.shape[1]\n",
    "    time_indices = np.arange(time_length)\n",
    "    window_starts = time_indices[0:time_length-window_length:int(0.5*window_length)]\n",
    "    for t in window_starts:\n",
    "        examples.append(data_i[:,t:t+window_length,:])\n",
    "        labels.append(label_i)\n",
    "        \n",
    "examples = np.array(examples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "assert examples.shape[0]==labels.shape[0]\n",
    "print(\"Total Examples: \", examples.shape[0])\n",
    "\n",
    "#shuffle the examples\n",
    "indices = np.arange(examples.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx = int(indices.shape[0]*0.6)\n",
    "valid_idx = int(indices.shape[0]*0.8)\n",
    "\n",
    "print(\"Train index: \", train_idx)\n",
    "print(\"Valid index: \", valid_idx)\n",
    "\n",
    "train_indices = indices[:train_idx]\n",
    "valid_indices = indices[train_idx:valid_idx]\n",
    "test_indices = indices[valid_idx:]\n",
    "\n",
    "examples_train = examples[train_indices]\n",
    "labels_train = labels[train_indices]\n",
    "examples_valid = examples[valid_indices]\n",
    "labels_valid = labels[valid_indices]\n",
    "examples_test = examples[test_indices]\n",
    "labels_test = labels[test_indices]\n",
    "\n",
    "#save preprocessed data\n",
    "with open(os.path.join(save_folder, \"examples_train.npy\"), 'wb') as f:\n",
    "    np.save(f, examples_train)\n",
    "with open(os.path.join(save_folder, \"examples_valid.npy\"), 'wb') as f:\n",
    "    np.save(f, examples_valid)\n",
    "with open(os.path.join(save_folder, \"examples_test.npy\"), 'wb') as f:\n",
    "    np.save(f, examples_test)\n",
    "with open(os.path.join(save_folder, \"labels_train.npy\"), 'wb') as f:\n",
    "    np.save(f, labels_train)\n",
    "with open(os.path.join(save_folder, \"labels_valid.npy\"),'wb') as f:\n",
    "    np.save(f, labels_valid)\n",
    "with open(os.path.join(save_folder, \"labels_test.npy\"),'wb') as f:\n",
    "    np.save(f, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd52a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63011215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5944ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28549db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e270a9",
   "metadata": {},
   "source": [
    "## Process of Orientation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e62e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"data/gordon/preprocessed/orien/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71d6a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:  1886243\n",
      "Unit time (s):  0.0016222724219519967\n"
     ]
    }
   ],
   "source": [
    "exps = []\n",
    "#Load experiments data\n",
    "for i in range(1,7):\n",
    "    exp = scipy.io.loadmat(os.path.join(folder, \"exp_%d_data.mat\"%i))\n",
    "    exps.append(exp)\n",
    "    \n",
    "#compute total time\n",
    "total_time = 0\n",
    "for i in range(6):\n",
    "    time_max = exps[i][\"mOr\"][:,1].max()\n",
    "    time_min = exps[i][\"mOr\"][:,1].min()\n",
    "    total_time += time_max-time_min\n",
    "    \n",
    "print(\"Total time: \", total_time)\n",
    "\n",
    "#compute unit time(s)\n",
    "#Total experiment time: 51min\n",
    "timeunit = (51*60)/total_time\n",
    "print(\"Unit time (s): \", timeunit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e80f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1\n",
      "Min length of Exp0: 2633\n",
      "Experiment 2\n",
      "Min length of Exp1: 2667\n",
      "Experiment 3\n",
      "Min length of Exp2: 2710\n",
      "Experiment 4\n",
      "Min length of Exp3: 2641\n",
      "Experiment 5\n",
      "Min length of Exp4: 2281\n"
     ]
    }
   ],
   "source": [
    "#Group configuration of agents\n",
    "groups = [[[1,2,3,4,5,6,7,9,10,11]],\n",
    "          [[1,2,3,4,5],[6,7,9,10,11]],\n",
    "          [[1,2,3],[4,5,6],[7,9],[10,11]],\n",
    "          [[1],[2],[3],[4],[5],[6],[7],[9],[10],[11]],\n",
    "          [[1,2,3,5],[4,6,7],[9,10,11]],\n",
    "          [[1,2,3,4,5,6],[7,9,10,11]]]\n",
    "\n",
    "group_relations = []\n",
    "mOr_data = []\n",
    "columns = [\"ExpID\",\"TS\",\"userID\",\"gID\",\"isLeader\", \"azimuth\", \"pitch\",\"roll\"]\n",
    "\n",
    "for exp_id in range(len(exps)-1):    \n",
    "    print(\"Experiment %d\"%(exp_id+1))\n",
    "    extract_mOr_expi = []\n",
    "    expi_df = pd.DataFrame(exps[exp_id][\"mOr\"], columns=columns)\n",
    "    #extract userIDs\n",
    "    userIDs = expi_df[\"userID\"].unique()\n",
    "    userIDs_map = {userID:idx for idx, userID in enumerate(userIDs)}\n",
    "        \n",
    "    #create group relations\n",
    "    gr_i = np.zeros((10,10))\n",
    "    groups_i = groups[exp_id]\n",
    "    groups_i_converted = []\n",
    "    for group in groups_i:\n",
    "        group_converted = [userIDs_map[user] for user in group]\n",
    "        groups_i_converted.append(group_converted)\n",
    "    for group in groups_i_converted:\n",
    "        for i in group:\n",
    "            for j in group:\n",
    "                gr_i[i,j]=1\n",
    "    group_relations.append(gr_i)\n",
    "    \n",
    "    #mapping userIDs in pandas dataframe\n",
    "    expi_df[\"userID_new\"] = expi_df[\"userID\"].apply(lambda x:userIDs_map[x])\n",
    "    expi_df[\"TS_new\"] = expi_df[\"TS\"].apply(lambda x:timeunit*x)\n",
    "    expi_df[\"Timestamp\"] = expi_df[\"TS_new\"].apply(lambda x: pd.Timestamp(x, unit='s'))\n",
    "    expi_df = expi_df.set_index(\"Timestamp\")\n",
    "    \n",
    "    #get common time interval\n",
    "    max_start = expi_df[expi_df[\"userID_new\"]==0].index.min()\n",
    "    min_end = expi_df[expi_df[\"userID_new\"]==0].index.max()\n",
    "    for userID in range(10):        \n",
    "        start = expi_df[expi_df[\"userID_new\"]==userID].index.min()\n",
    "        end = expi_df[expi_df[\"userID_new\"]==userID].index.max()\n",
    "        if start > max_start:\n",
    "            max_start = start\n",
    "        if end < min_end:\n",
    "            min_end = end  \n",
    "            \n",
    "    for userID in range(10):    \n",
    "        expi_df_userID = expi_df[expi_df.userID_new==userID]\n",
    "        resampled = expi_df_userID[expi_df_userID.userID_new==userID].resample(\"200ms\", origin=max_start).mean()\n",
    "        resampled = resampled.interpolate()#interpolate nan values\n",
    "        data = resampled[[\"azimuth\"]].values\n",
    "        extract_mOr_expi.append(data)\n",
    "        \n",
    "    #compute length\n",
    "    min_length = np.inf    \n",
    "    for i in range(len(extract_mOr_expi)):\n",
    "        data = extract_mOr_expi[i]\n",
    "        length = data.shape[0]\n",
    "        if length < min_length:\n",
    "            min_length = length\n",
    "            \n",
    "    print(\"Min length of Exp%d:\"%exp_id, min_length)    \n",
    "    for i in range(len(extract_mOr_expi)):\n",
    "        data = extract_mOr_expi[i]\n",
    "        data = data[:min_length]\n",
    "        extract_mOr_expi[i] = data\n",
    "        \n",
    "    extract_mOr_expi = np.array(extract_mOr_expi)   \n",
    "    mOr_data.append(extract_mOr_expi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76af58aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Examples:  1286\n",
      "Train index:  771\n",
      "Valid index:  1028\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "labels = []\n",
    "\n",
    "window_length = 20\n",
    "\n",
    "for expID in range(5):\n",
    "    data_i = mOr_data[expID]\n",
    "    label_i = group_relations[expID]\n",
    "    \n",
    "    time_length = data_i.shape[1]\n",
    "    time_indices = np.arange(time_length)\n",
    "    window_starts = time_indices[0:time_length-window_length:int(0.5*window_length)]\n",
    "    for t in window_starts:\n",
    "        examples.append(data_i[:,t:t+window_length,:])\n",
    "        labels.append(label_i)\n",
    "        \n",
    "examples = np.array(examples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "assert examples.shape[0]==labels.shape[0]\n",
    "print(\"Total Examples: \", examples.shape[0])\n",
    "\n",
    "#shuffle the examples\n",
    "indices = np.arange(examples.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx = int(indices.shape[0]*0.6)\n",
    "valid_idx = int(indices.shape[0]*0.8)\n",
    "\n",
    "print(\"Train index: \", train_idx)\n",
    "print(\"Valid index: \", valid_idx)\n",
    "\n",
    "train_indices = indices[:train_idx]\n",
    "valid_indices = indices[train_idx:valid_idx]\n",
    "test_indices = indices[valid_idx:]\n",
    "\n",
    "examples_train = examples[train_indices]\n",
    "labels_train = labels[train_indices]\n",
    "examples_valid = examples[valid_indices]\n",
    "labels_valid = labels[valid_indices]\n",
    "examples_test = examples[test_indices]\n",
    "labels_test = labels[test_indices]\n",
    "\n",
    "#save preprocessed data\n",
    "with open(os.path.join(save_folder, \"examples_train.npy\"), 'wb') as f:\n",
    "    np.save(f, examples_train)\n",
    "with open(os.path.join(save_folder, \"examples_valid.npy\"), 'wb') as f:\n",
    "    np.save(f, examples_valid)\n",
    "with open(os.path.join(save_folder, \"examples_test.npy\"), 'wb') as f:\n",
    "    np.save(f, examples_test)\n",
    "with open(os.path.join(save_folder, \"labels_train.npy\"), 'wb') as f:\n",
    "    np.save(f, labels_train)\n",
    "with open(os.path.join(save_folder, \"labels_valid.npy\"),'wb') as f:\n",
    "    np.save(f, labels_valid)\n",
    "with open(os.path.join(save_folder, \"labels_test.npy\"),'wb') as f:\n",
    "    np.save(f, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c68ecdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/gordon/preprocessed/orien/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a2dbc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8746f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcebd6a3",
   "metadata": {},
   "source": [
    "## Test of DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829d60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af2f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = load_gordon(suffix=\"orien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee919bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ee81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
